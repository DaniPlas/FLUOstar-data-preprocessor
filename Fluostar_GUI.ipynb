{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/alnair/Desktop/2022_02_21_TADC_benchmarking_highconc/20220221_TADC_benchmarking_higher_conc_01.xlsx\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "#TODO: check if import sts could be optimized only importing used functions\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog as fd\n",
    "from tkinter import ttk\n",
    "\n",
    "## main functions\n",
    "\n",
    "# retrieve documents' addresses + add them to a dict \n",
    "def document_retrieval():\n",
    "    doc_dict = {}\n",
    "    number_of_docs = int(input('How many documents will you merge? '))\n",
    "    \n",
    "    for i in range(0, number_of_docs):\n",
    "        \n",
    "        doc_dict['doc_' + str(i + 1)] = fd.askopenfilename()\n",
    "    \n",
    "    return doc_dict\n",
    "\n",
    "# aim: renaming columns to letter+number format from FLUOstar\n",
    "#this really could be improved\n",
    "def column_rename(df):\n",
    "    for i in range(1,97):\n",
    "        letters = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']\n",
    "        if int(i%12) == 0:\n",
    "            letter = letters[int(i/12)-1]\n",
    "            number = 12\n",
    "        else:\n",
    "            letter = letters[int(i/12)]\n",
    "            number = i%12\n",
    "    \n",
    "        df.columns.values[i] = letter + str(number)   \n",
    "    \n",
    "    return df\n",
    "\n",
    "# getting number of rows in doc for preprocessing/adding conditions later on (I think...)\n",
    "def row_numbers(df):\n",
    "    row_number = len(df.index)\n",
    "    df.index = range(1, row_number + 1)\n",
    "    return df\n",
    "\n",
    "\n",
    "# preprocessing of datasets: dropping top rows and naming TIME column.\n",
    "def preprocessing(df):\n",
    "    df = df.drop([0,1,2,3,4,5,6], axis=0)\n",
    "    df = df.drop(columns=['User: USER'])\n",
    "    df = df.rename({'Unnamed: 1': 'Time'}, axis=1) \n",
    "    df = column_rename(df)\n",
    "    df = df.astype(float)\n",
    "    df = row_numbers(df)\n",
    "    return df\n",
    "\n",
    "# add final time of previous dataframe to time column of next dataframe\n",
    "def time_column_update(first_df, second_df):\n",
    "    current_last_time = first_df['Time'][first_df.index[-1]]\n",
    "    second_df['Time'] = second_df['Time'].apply(lambda x: x + current_last_time)\n",
    "    return second_df\n",
    "\n",
    "# create full time column for the entire experiment\n",
    "def time_processing_doc():\n",
    "    all_docs_final = {}\n",
    "    all_docs_preproc_keys = list(all_docs_dict_preprocessed.keys())\n",
    "    \n",
    "    for i in range(0, len(all_docs_preproc_keys)):\n",
    "        if i==0:\n",
    "            key_value = all_docs_preproc_keys[i]\n",
    "            all_docs_final[key_value] = all_docs_dict_preprocessed[key_value]\n",
    "        \n",
    "        elif i>0:\n",
    "            first_key_value = all_docs_preproc_keys[i-1]\n",
    "            second_key_value = all_docs_preproc_keys[i]\n",
    "            first_doc_db = all_docs_dict_preprocessed[first_key_value]\n",
    "            second_doc_db = all_docs_dict_preprocessed[second_key_value]\n",
    "            all_docs_final[second_key_value] = time_column_update(first_doc_db, second_doc_db)\n",
    "            \n",
    "    return all_docs_final\n",
    "\n",
    "# concantenate all docs in one dataframe\n",
    "def concatenate_docs():\n",
    "    all_docs = []\n",
    "\n",
    "    for i in all_docs_final_dict.keys():\n",
    "        current_final_doc = all_docs_final_dict[i]\n",
    "        all_docs.append(current_final_doc)\n",
    "    \n",
    "    return all_docs\n",
    "\n",
    "# asks for user input regarding columns that belong to the (current) group/condition\n",
    "def choose_groups():\n",
    "    columns_string = input(\"Write the name of the columns that belong to this group as the cell name (ex. B2 B3 B4), separated by spaces: \")\n",
    "    columns_list = columns_string.split(\" \")\n",
    "\n",
    "    # QC: check for unique column names + valid names\n",
    "    # finally check if name is unique\n",
    "    for name in columns_list:\n",
    "        name_regex = re.search(\"\\A[a-h][1-9]$|\\A[a-h]1[0-2]$\", name, re.IGNORECASE)\n",
    "        if name_regex == False:\n",
    "            print(\"The column\" + name + \"does not match the correct naming pattern (ex. B4, c2). Please, enter the columns for this condition again\" )\n",
    "            columns_string = input(\"Write the name of the columns that belong to this group as the cell name (ex. B2 B3 B4), separated by spaces: \")\n",
    "\n",
    "    return columns_list\n",
    "\n",
    "# creates condition groups + columns that belong in them by asking for user input\n",
    "# this needs optimization but works\n",
    "def create_groups():\n",
    "    conditions_groups = {}\n",
    "    entering_groups_active = True\n",
    "   \n",
    "    while entering_groups_active:\n",
    "        group_name = input(\"Write a name for this group of columns: \")\n",
    "        columns_list = choose_groups()\n",
    "\n",
    "        # QC for unique names\n",
    "        conditions_groups_list = list(conditions_groups.values())\n",
    "        for column in columns_list:\n",
    "            if column in conditions_groups_list:\n",
    "                print(\"It seems as if one or more of the columns have already been chosen. Please enter the columns for this condition again.\")\n",
    "                columns_list = choose_groups()\n",
    "\n",
    "        conditions_groups[group_name] = columns_list\n",
    "\n",
    "        # new group input + answer check\n",
    "        new_group = input(\"Would you like to add another group? (y/n) \").lower()\n",
    "        if new_group == 'y' or new_group == 'yes':\n",
    "            entering_groups_active = True\n",
    "        elif new_group == 'n' or new_group == 'no':\n",
    "            entering_groups_active = False\n",
    "        else:\n",
    "            print(\"You must write 'y' (without ticks) if you want to add another group, and 'n' (without ticks) if you do not wish to do so\")\n",
    "            new_group = input(\"Would you like to add another group? (y/n) \")\n",
    "            if new_group == 'y' or new_group == 'yes':\n",
    "                entering_groups_active = True\n",
    "            elif new_group == 'n' or new_group == 'no':\n",
    "                entering_groups_active = False\n",
    "    \n",
    "    return conditions_groups\n",
    "\n",
    "# retrieves which wells will be kept on df according to chosen columns by user\n",
    "def get_wells_to_keep(conditions_groups):\n",
    "    chosen_wells = []\n",
    "    \n",
    "    for conditions in conditions_groups.values():\n",
    "        for i in range(len(conditions)):\n",
    "            chosen_wells.append(conditions[i].upper())\n",
    "            \n",
    "    return chosen_wells\n",
    "\n",
    "# eliminates wells that do not belong to any group/condition\n",
    "def drop_unused_wells(df, wells_list):\n",
    "    columns_df = list(df.columns)\n",
    "    \n",
    "    for well in columns_df[1:]:\n",
    "        if str(well) not in wells_list:\n",
    "            del df[well]\n",
    "    \n",
    "    return df\n",
    "\n",
    "# creates plots for every condition, showing all columns for each one\n",
    "def create_first_plots():\n",
    "    \n",
    "    full_plots_dic = {}\n",
    "    axs_dic = {}\n",
    "    time_col = full_doc['Time']\n",
    "    fluorophore = input('Which fluorophore was used? ')\n",
    "        \n",
    "    for group in conditions_groups.keys():\n",
    "        first = conditions_groups.get(group)[0].upper()\n",
    "        second = conditions_groups.get(group)[1].upper()\n",
    "        third = conditions_groups.get(group)[2].upper()\n",
    "        full_plots_dic[group + '_plot'] = plt.plot(time_col, full_doc[first], time_col, full_doc[second], time_col, full_doc[third], label=group)\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel(fluorophore + ' intensity (arb. units)')\n",
    "        plt.title(str(group))\n",
    "        full_plots_fig = plt.figure(tight_layout=True)\n",
    "        \n",
    "    return full_plots_dic\n",
    "\n",
    "# deletes wells (after user input) if its needed (ex. if a replicate seems wrong)\n",
    "def deleting_wells(wtk):\n",
    "    wtk_up = wtk[:]\n",
    "    delete_wells_active = True\n",
    "    wells_to_del_list = []\n",
    "    \n",
    "    # get input for wells to be deleted\n",
    "    while delete_wells_active:\n",
    "        delete_answer = input(\"Do you want to delete any well? (y/n) \")\n",
    "        if delete_answer.lower() == 'y' or delete_answer.lower() == 'yes':\n",
    "            wells_to_del = input('Which wells? Write them separated by a space ')\n",
    "            wells_to_del_list = wells_to_del.split(\" \")\n",
    "        elif delete_answer.lower() == 'n' or delete_answer.lower() == 'no':\n",
    "            delete_wells_active = False\n",
    "        else:\n",
    "            print(\"You must write 'y' (without ticks) if you want to delete any wells, and 'n' (without ticks) if you do not wish to do so\")\n",
    "            delete_answer = input(\"Do you want to delete any well? (y/n) \")\n",
    "            if delete_answer.lower() == 'y' or delete_answer.lower() == 'yes':\n",
    "                delete_wells_active = True\n",
    "            elif delete_answer.lower() == 'n' or delete_answer.lower() == 'no':\n",
    "                delete_wells_active = False\n",
    "      \n",
    "        # delete chosen wells\n",
    "        for well in wells_to_del_list:\n",
    "            if well.upper() in wtk_up:\n",
    "                wtk_up.remove(well.upper())\n",
    "                \n",
    "    return wtk_up\n",
    "\n",
    "# update groups taking out deleted wells\n",
    "def update_conditions_groups(cg):\n",
    "    \n",
    "    for condition, values in cg.items():\n",
    "        value_list = values[:]\n",
    "        for item in value_list:\n",
    "            if item.upper() not in wells_to_keep_updated:\n",
    "                print(item)\n",
    "                values.remove(item)\n",
    "                \n",
    "    return cg\n",
    "\n",
    "#changes name of columns according to group/condition name\n",
    "def change_column_names(df):\n",
    "    column_names = {}\n",
    "    new_df = df.copy()\n",
    "    new_df = new_df.set_index('Time')\n",
    "    \n",
    "    for key, value in conditions_groups.items():\n",
    "        for i in range(0, len(value)):\n",
    "            column_names[value[i]] = key\n",
    "    \n",
    "    for df_column in list(new_df.columns):\n",
    "        for key, value in column_names.items(): \n",
    "            if df_column.lower() == key.lower():\n",
    "                new_df.rename(columns = {df_column: value}, inplace = True)\n",
    "            elif df_column.lower() == key.lower() + \"_std\":\n",
    "                new_df.rename(columns = {df_column: value + '_std'}, inplace = True)\n",
    "    \n",
    "    return new_df\n",
    "\n",
    "# returns df with averages for each group/condition\n",
    "def averages_df_gen(df):\n",
    "    \n",
    "    averages_df =df.groupby(level=0,axis=1).mean()        \n",
    "    return averages_df\n",
    "\n",
    "# returns df with standar deviations for each group/condition\n",
    "def stdev_df_gen(df):\n",
    "    \n",
    "    stdev_df =df.groupby(level=0,axis=1).std()\n",
    "            \n",
    "    return stdev_df\n",
    "\n",
    "# returns df with averages + standar deviations for each condition (general format for each condition: ave column - stdev column)\n",
    "def merge_ave_std(ave_df, std_df):\n",
    "    ini_col = len(conditions_groups)\n",
    "    num = 1\n",
    "    \n",
    "    for i in range(0, ini_col):\n",
    "        std_col = std_df.columns[i]\n",
    "        if i == 0:\n",
    "            ave_col = ave_df.columns[i]\n",
    "            if ave_col == std_col:\n",
    "                ave_df.insert(i + 1, (std_df.columns[i] + '_std'), std_df[std_df.columns[i]])\n",
    "        else:\n",
    "            ave_col = ave_df.columns[i + num]\n",
    "            if ave_col == std_col:\n",
    "                ave_df.insert(i+num+1, (std_df.columns[i] + '_std'), std_df[std_df.columns[i]])\n",
    "                num += 1\n",
    "    \n",
    "    return ave_df\n",
    "\n",
    "# asks user input for initial and final times for normalization of each column/replicate\n",
    "def get_norm_times(df):\n",
    "    times_norm = {}\n",
    "    new_df = df.copy() \n",
    "    \n",
    "    for i in range(1, len(df.columns)):\n",
    "        ini_time = int(input('Enter initial time for normalization of column ' + str(df.columns[i] )))\n",
    "        final_time = int(input('Enter final time for normalization of column ' + str(df.columns[i] )))\n",
    "        times_norm[new_df.columns[i]] = [0]*2\n",
    "        times_norm[new_df.columns[i]][0] = ini_time\n",
    "        times_norm[new_df.columns[i]][1] = final_time \n",
    "                         \n",
    "    return times_norm      \n",
    "\n",
    "# returns normalized df using initial and final times input by user\n",
    "def normalization(df): \n",
    "    \n",
    "    for i in range(0, len(df.columns) - 1):\n",
    "        #look for initial and final chosen times\n",
    "        column_in_dic = list(times_norm_dic.keys())[i]\n",
    "        ini_time = times_norm_dic[column_in_dic][0]\n",
    "        final_time = times_norm_dic[column_in_dic][1]\n",
    "        \n",
    "        #look for indexes that match ini and final times in Time column\n",
    "        ini_index = df.loc[df['Time'] == ini_time].index[0]\n",
    "        final_index = df.loc[df['Time'] == final_time].index[0]\n",
    "        \n",
    "        #look for max and min values in df column within range= ini_index-final_index\n",
    "        max_value = df.iloc[ini_index:final_index, i+1].max()\n",
    "        min_value = df.iloc[ini_index:final_index, i+1].min()\n",
    "        subs_max_min  = max_value - min_value\n",
    "\n",
    "        final_index_norm = final_index + 1\n",
    "        \n",
    "        #normalize each value in sample column\n",
    "        for k in range(ini_index, final_index_norm):\n",
    "            current_value = df.at[k, column_in_dic]\n",
    "            df.at[k, column_in_dic] = (current_value - min_value)/subs_max_min\n",
    "        \n",
    "    #get lowest and highest times used in df\n",
    "    lower_times = []\n",
    "    highest_times = []\n",
    "    \n",
    "    for condition in list(times_norm_dic.keys()):\n",
    "        lower_time = times_norm_dic[condition][0]\n",
    "        highest_time = times_norm_dic[condition][1]\n",
    "        lower_times.append(lower_time)\n",
    "        highest_times.append(highest_time)\n",
    "    \n",
    "    min_time = min(lower_times)\n",
    "    max_time = max(highest_times)\n",
    "    min_index = df.loc[df['Time'] == min_time].index[0]\n",
    "    max_index = df.loc[df['Time'] == max_time].index[0]\n",
    "    last_index = len(df.index)\n",
    "    min_index_updated = min_index\n",
    "    max_index_updated = max_index - min_index_updated\n",
    "    last_index_updated = last_index - min_index_updated + 1\n",
    "    first_range = range(0, (min_index + 1))\n",
    "    last_range = range(max_index_updated, (last_index_updated + 1))\n",
    "    df.drop(df.iloc[0:min_index_updated].index, inplace=True)\n",
    "    df.drop(df.iloc[max_index_updated:last_index_updated].index, inplace=True)\n",
    "\n",
    "    \n",
    "    return df\n",
    "\n",
    "# calculate half-times for each column/replicate and returns a df (format: column with each replicate in rows - half times)\n",
    "def half_times_df(df):\n",
    "    \n",
    "    val = 0.5\n",
    "    \n",
    "    half_times = df.sub(val).abs().idxmin()\n",
    "    \n",
    "    return half_times\n",
    "\n",
    "\n",
    "#################################################################################################################################\n",
    "\n",
    "## full sequence \n",
    "\n",
    "# retrieve all documents\n",
    "all_docs_dict = document_retrieval()\n",
    "all_docs_keys = all_docs_dict.keys()\n",
    "all_docs_dict_preprocessed = {}\n",
    "\n",
    "# add documents to dictionary with all docs preprocessed\n",
    "for i in all_docs_keys:\n",
    "    current_doc_add = all_docs_dict[i]\n",
    "    current_doc_db = pd.read_excel(current_doc_add)\n",
    "    all_docs_dict_preprocessed[i] = preprocessing(current_doc_db)\n",
    "\n",
    "# check what is this truly doing\n",
    "all_docs_final_dict = time_processing_doc()\n",
    "all_docs_list = concatenate_docs()\n",
    "\n",
    "# create full docs with all docs all preprocessed\n",
    "full_doc = pd.concat(all_docs_list)\n",
    "\n",
    "# ask and create conditions groups with replicates + define wells/columns to be kept\n",
    "conditions_groups = create_groups()\n",
    "wells_to_keep = get_wells_to_keep(conditions_groups)\n",
    "\n",
    "# eliminate unused wells from full docs\n",
    "full_doc = drop_unused_wells(full_doc, wells_to_keep)\n",
    "\n",
    "# show plots for all conditions using all wells\n",
    "create_first_plots()\n",
    "\n",
    "# ask user if any wells will be deleted and update full doc df + condition group dict accordingly\n",
    "wells_to_keep_updated = deleting_wells(wells_to_keep)\n",
    "full_doc = drop_unused_wells(full_doc, wells_to_keep_updated)\n",
    "conditions_groups_up = conditions_groups.copy()\n",
    "conditions_groups_up = update_conditions_groups(conditions_groups_up)\n",
    "\n",
    "# change name of full doc creating a new updated df\n",
    "full_doc_good_names = change_column_names(full_doc)\n",
    "\n",
    "# generate df with average for all conditions\n",
    "averages_df = averages_df_gen(full_doc_good_names)\n",
    "\n",
    "# generate plot with averages\n",
    "average_plot = averages_df.plot()\n",
    "\n",
    "# generate df with standar deviations for all conditions\n",
    "stdev_df = stdev_df_gen(full_doc_good_names)\n",
    "\n",
    "# generate plot with averages + std deviations\n",
    "average_plot_sd = averages_df.plot(yerr=stdev_df)\n",
    "\n",
    "# generate df with both averages and standar deviations\n",
    "averages_std_df = merge_ave_std(averages_df, stdev_df)\n",
    "\n",
    "# ask user input for initial and final times for normalization of each replicate, put info in a dictionary\n",
    "times_norm_dic = get_norm_times(full_doc)\n",
    "\n",
    "# generate df with normalized data\n",
    "norm_df = full_doc.copy()\n",
    "norm_df = norm_df.reset_index(drop=True)\n",
    "norm_df = normalization(norm_df)\n",
    "norm_df = change_column_names(norm_df)\n",
    "\n",
    "# generate df with averages of normalized data\n",
    "norm_averages_df = averages_df_gen(norm_df)\n",
    "# generate df with standar deviations of normalized data\n",
    "norm_stdev_df = stdev_df_gen(norm_df)\n",
    "\n",
    "# plot normalized data (averages + stdev)\n",
    "norm_average_plot = norm_averages_df.plot(yerr=norm_stdev_df)\n",
    "\n",
    "# generates df with averages + stdevs of normalized data\n",
    "norm_ave_std_df = merge_ave_std(norm_averages_df, norm_stdev_df)\n",
    "\n",
    "# check what is happ here---\n",
    "norm_std_ave_df = averages_df_gen(norm_stdev_df)\n",
    "\n",
    "\n",
    "# calculate half-times + generate df with them\n",
    "half_times = half_times_df(norm_df)\n",
    "half_times = half_times.reset_index()\n",
    "half_times = half_times.rename(columns={half_times.columns[0]: 'Condition', half_times.columns[1]: 'half-times'})\n",
    "\n",
    "# calculate and generate averages + std devs for half times\n",
    "half_times_ave = half_times.groupby(by='Condition').mean()\n",
    "half_times_stdev = half_times.groupby(by='Condition').std()\n",
    "half_times_stdev = half_times_stdev.rename(columns={half_times.columns[1]: 'half-times stdev'})\n",
    "ht_std_column = half_times_stdev['half-times stdev']\n",
    "half_times_ave_std = half_times_ave.join(ht_std_column)\n",
    "\n",
    "# generate final excel file\n",
    "final_doc_name = input('Name for the final Excel document: ')\n",
    "\n",
    "with pd.ExcelWriter(final_doc_name + '.xlsx') as writer:\n",
    "    full_doc_good_names.to_excel(writer, sheet_name=\"Full\")  \n",
    "    averages_std_df.to_excel(writer, sheet_name=\"Averages\")  \n",
    "    norm_df.to_excel(writer, sheet_name=\"Normalized\")  \n",
    "    norm_ave_std_df.to_excel(writer, sheet_name=\"Normalized (ave)\")\n",
    "    half_times.to_excel(writer, sheet_name=\"half-times\")\n",
    "    half_times_ave_std.to_excel(writer, sheet_name=\"half-times (ave)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13c2dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## GUI\n",
    "\n",
    "# Window\n",
    "\n",
    "# create window\n",
    "root = tk.Tk()\n",
    "root.title(\"FLUOstar data preprocessor\")\n",
    "\n",
    "# specify window's measures and location\n",
    "root_width = 600\n",
    "root_height = 425\n",
    "\n",
    "screen_width = root.winfo_screenwidth()\n",
    "screen_height = root.winfo_screenheight()\n",
    "\n",
    "center_x = int(screen_width/2 - root_width/2)\n",
    "center_y = int(screen_height/2 - root_height/2)\n",
    "\n",
    "root.geometry(f'{root_width}x{root_height}+{center_x}+{center_y}')\n",
    "\n",
    "# stacking fixed on top\n",
    "root.attributes('-topmost', 1)\n",
    "\n",
    "# \n",
    "\n",
    "root.mainloop()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "a8d65dcadb6319e643df42f085a0e6b87041db646e7526c1d08e774651413a81"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
